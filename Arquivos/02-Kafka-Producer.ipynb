{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "224d912c",
   "metadata": {},
   "source": [
    "<!-- Projeto Desenvolvido na Data Science Academy - www.datascienceacademy.com.br -->\n",
    "# <font color='blue'>Data Science Academy</font>\n",
    "## <font color='blue'>PySpark e Apache Kafka Para Processamento de Dados em Batch e Streaming</font>\n",
    "## <font color='blue'>Projeto 6</font>\n",
    "### <font color='blue'>Monitoramento de Criptomoedas em Tempo Real com Kafka, MongoDB e Streamlit</font>\n",
    "### <font color='blue'>Criação do Producer Kafka</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "047cca56-83d4-4203-888c-08c56efe1916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json\n",
    "import time \n",
    "import requests\n",
    "import pandas as pd\n",
    "from kafka import KafkaProducer\n",
    "from datetime import datetime\n",
    "from json import dumps\n",
    "from configparser import RawConfigParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e96dc2aa-1a30-4631-be26-53a5f089780c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dsa_config.conf']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carrega o arquivo de configuração\n",
    "config_local = RawConfigParser()\n",
    "config_local.read(\"dsa_config.conf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c6b8c5-a3f2-4fe0-8d45-e4b5b38e4f4b",
   "metadata": {},
   "source": [
    "Inicialização do Kafka Producer\n",
    "<!-- Projeto Desenvolvido na Data Science Academy - www.datascienceacademy.com.br -->\n",
    "- O KafkaProducer é inicializado com bootstrap_servers apontando para os brokers do Kafka e value_serializer é usado para serializar dados (objetos Python) no formato JSON e codificá-los em bytes antes de enviá-los ao Kafka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0322e8c7-144d-44d0-94f4-860e520f5776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos as configurações\n",
    "server = config_local['Host']['ip']\n",
    "port = config_local['Host']['port']\n",
    "server = [f\"{server}:{port}\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13a0783",
   "metadata": {},
   "source": [
    "Codificamos as mensagens em UTF-8 para que elas possam ser enviadas corretamente ao Kafka e qualquer consumidor que leia essas mensagens possa decodificá-las como UTF-8 JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53a66f6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoBrokersAvailable",
     "evalue": "NoBrokersAvailable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoBrokersAvailable\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Cria o producer\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m dsa_producer \u001b[38;5;241m=\u001b[39m KafkaProducer(bootstrap_servers \u001b[38;5;241m=\u001b[39m server, value_serializer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x:dumps(x)\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\kafka\\producer\\kafka.py:381\u001b[0m, in \u001b[0;36mKafkaProducer.__init__\u001b[1;34m(self, **configs)\u001b[0m\n\u001b[0;32m    378\u001b[0m reporters \u001b[38;5;241m=\u001b[39m [reporter() \u001b[38;5;28;01mfor\u001b[39;00m reporter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric_reporters\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metrics \u001b[38;5;241m=\u001b[39m Metrics(metric_config, reporters)\n\u001b[1;32m--> 381\u001b[0m client \u001b[38;5;241m=\u001b[39m KafkaClient(metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metrics, metric_group_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproducer\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    382\u001b[0m                      wakeup_timeout_ms\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_block_ms\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    383\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig)\n\u001b[0;32m    385\u001b[0m \u001b[38;5;66;03m# Get auto-discovered version from client if necessary\u001b[39;00m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_version\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\kafka\\client_async.py:244\u001b[0m, in \u001b[0;36mKafkaClient.__init__\u001b[1;34m(self, **configs)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_version\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    243\u001b[0m     check_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_version_auto_timeout_ms\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m--> 244\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_version\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_version(timeout\u001b[38;5;241m=\u001b[39mcheck_timeout)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\kafka\\client_async.py:927\u001b[0m, in \u001b[0;36mKafkaClient.check_version\u001b[1;34m(self, node_id, timeout, strict)\u001b[0m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;66;03m# Timeout\u001b[39;00m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    926\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m--> 927\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Errors\u001b[38;5;241m.\u001b[39mNoBrokersAvailable()\n",
      "\u001b[1;31mNoBrokersAvailable\u001b[0m: NoBrokersAvailable"
     ]
    }
   ],
   "source": [
    "# Cria o producer\n",
    "dsa_producer = KafkaProducer(bootstrap_servers = server, value_serializer = lambda x:dumps(x).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aa1dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dsa_producer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8330a277-7116-49d4-8de0-f13f42696dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a função para obter dados de criptomoedas através da API\n",
    "def dsacryptoApi():\n",
    "    \n",
    "    # Obtém a URL da API de criptomoedas a partir da configuração local\n",
    "    url = config_local['CryptoCoinAPI']['url']\n",
    "    \n",
    "    # Faz uma requisição GET para a URL da API\n",
    "    response = requests.get(url)      \n",
    "    \n",
    "    # Converte a resposta da API para o formato JSON\n",
    "    resultado = response.json()          \n",
    "    \n",
    "    # Captura o timestamp atual no formato \"YYYY-MM-DD HH:MM:SS\"\n",
    "    current_timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # Inicializa um dicionário para armazenar os dados do top 10\n",
    "    top_10 = {}\n",
    "    \n",
    "    # Adiciona o timestamp atual ao dicionário\n",
    "    top_10['timestamp'] = current_timestamp\n",
    "    \n",
    "    # Adiciona os dados das 10 principais criptomoedas retornadas pela API\n",
    "    top_10['data'] = resultado['data'][:10]   \n",
    "    \n",
    "    # Envia os dados do top 10 para o tópico Kafka\n",
    "    dsa_producer.send('dsa-p6-crypto-topic', value = top_10)\n",
    "    \n",
    "    # Retorna os dados do top 10 como resultado da função\n",
    "    return top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfdbb43-5912-4bb8-823f-2f719653f87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chama a função 25 vezes com um intervalo de 15 segundos entre cada chamada.\n",
    "# Altere a condição para while(True) para buscar continuamente dados em tempo real.\n",
    "# Fique atento aos limites da API.\n",
    "\n",
    "counter = 0\n",
    "#while(True):\n",
    "while(counter < 25):\n",
    "    counter = counter + 1\n",
    "    print(f\"Chamando a Função Para Extrair Dados em Tempo Real. Contador: {counter}\")\n",
    "    dsacryptoApi()\n",
    "    print(\"Aguardando 15 segundos...\")\n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4a7dbd",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
